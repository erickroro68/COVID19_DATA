import pandas as pd

# Load the COVID-19 dataset
df = pd.read_csv('time_series_covid19_confirmed_US.csv')

# Show the column names and first few rows
print("Column names:", df.columns)
print("\nFirst 5 rows of the dataset:")
print(df.head())

# Check data types and missing values
print("\nDataset structure:")
df.info()

print("\nMissing values in each column:")
print(df.isnull().sum())

 #DATA CLEANING
 
# Fill missing values with 0 or drop if appropriate
df.fillna(0, inplace=True)

# Drop duplicate rows if any
df.drop_duplicates(inplace=True)

# Convert columns to appropriate data types if necessary
df['FIPS'] = pd.to_numeric(df['FIPS'], errors='coerce')

#Exploratory Analysis

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.dates as mdates

# Load the COVID-19 dataset
df = pd.read_csv('time_series_covid19_confirmed_US.csv')

# Extract the date columns (they start from the 12th column onward)
dates = pd.to_datetime(df.columns[11:], format='%m/%d/%y')  # Convert columns to datetime format

# 1. What are the column names of the dataset?
print("Column names:", df.columns)
#Index(['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State',
       'Country_Region', 'Lat', 'Long_', '1/22/20', '1/23/20', ...],
      dtype='object', length=1154)


# 2. What is the structure of the dataset? (data types of each column)
print("\nDataset structure:")
df.info()
#<class 'pandas.core.frame.DataFrame'>
#RangeIndex: 3342 entries, 0 to 3341
#Columns: 1154 entries, UID to 3/9/23
#dtypes: float64(3), int64(1145), object(6)
#memory usage: 29.4+ MB



# 3. What is the summary statistics of numerical columns?
print("\nSummary statistics:")
print(df.describe())
#                   UID        code3          FIPS          Lat        Long_      1/22/20      1/23/20  ...        3/3/23        3/4/23        3/5/23        3/6/23        3/7/23        3/8/23        3/9/23
#count     3.342000e+03  3342.000000   3332.000000  3342.000000  3342.000000  3342.000000  3342.000000  ...  3.342000e+03  3.342000e+03  3.342000e+03  3.342000e+03  3.342000e+03  3.342000e+03  3.342000e+03
#mean      8.342992e+07   834.494913  33043.078932    36.721617   -88.642045     0.000299     0.000299  ...  3.101397e+04  3.101461e+04  3.101346e+04  3.101602e+04  3.102660e+04  3.104601e+04  3.106005e+04
#std       4.314076e+06    36.487378  18648.808931     9.079322    21.776287     0.017298     0.017298  ...  1.083087e+05  1.083093e+05  1.083090e+05  1.083152e+05  1.083322e+05  1.083601e+05  1.084494e+05
#min       1.600000e+01    16.000000     60.000000   -14.271000  -174.159600     0.000000     0.000000  ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00



# 4. How many missing values are in each column?
print("\nMissing values in each column:")
print(df.isnull().sum())
# UID        0
#iso2       0
#iso3       0
#code3      0
#FIPS      10
#1/22/20    0
#1/23/20    0
...



# 5. What are the unique values in the 'Province_State' column?
print("\nUnique values in 'Province_State' column:")
print(df['Province_State'].unique())
#['Alabama' 'Alaska' 'American Samoa' 'Arizona' 'Arkansas' 'California'
#'Colorado' 'Connecticut' 'Delaware' 'Diamond Princess' 'District of Columbia' 
#'Florida' 'Georgia' 'Grand Princess' 'Guam' 'Hawaii' 'Idaho' 'Illinois' 
#'Indiana' 'Iowa' 'Kansas' 'Kentucky' 'Louisiana' 'Maine' 'Maryland' 
#'Massachusetts' 'Michigan' 'Minnesota' 'Mississippi' 'Missouri' 'Montana' 
#'Nebraska' 'Nevada' 'New Hampshire' 'New Jersey' 'New Mexico' 'New York' 
#'North Carolina' 'North Dakota' 'Northern Mariana Islands' 'Ohio' 'Oklahoma' 
#'Oregon' 'Pennsylvania' 'Puerto Rico' 'Rhode Island' 'South Carolina' 
#'South Dakota' 'Tennessee' 'Texas' 'Utah' 'Vermont' 'Virgin Islands' 
#'Virginia' 'Washington' 'West Virginia' 'Wisconsin' 'Wyoming']


  
# 6. How many records are there in the dataset?
print("\nNumber of records:", len(df))
#3342



# 7. What are the first 5 rows of the dataset?
print("\nFirst 5 rows:")
print(df.head())

#     UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region        Lat      Long_  ... 2/28/23  3/1/23  3/2/23  3/3/23  3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23
#3341  84056045   US  USA    840  56045.0      Weston        Wyoming             US  43.839612 -104.567488  ...    1905    1905    1905    1905    1905    1905    1905    1905    1905    1905


# 8. What are the last 5 rows of the dataset?
print("\nLast 5 rows:")
print(df.tail())



# 9. What is the range of confirmed cases in the dataset (min and max)?
confirmed_min = df.iloc[:, 11:].min().min()
confirmed_max = df.iloc[:, 11:].max().max()
print("\nRange of confirmed cases:", confirmed_min, confirmed_max)
#Min: -3073, Max: 3710586
#14087.610530992124

# 10. What is the average number of confirmed cases per day?
daily_avg_confirmed = df.iloc[:, 11:].mean().mean()
print("\nAverage daily confirmed cases:", daily_avg_confirmed)
#14087.610530992124



# 11. What is the median number of confirmed cases per day?
daily_median_confirmed = df.iloc[:, 11:].median().median()
print("\nMedian daily confirmed cases:", daily_median_confirmed)
#2662.5



# 12. What is the variance of confirmed cases over time?
daily_var_confirmed = df.iloc[:, 11:].var().var()
print("\nVariance of daily confirmed cases:", daily_var_confirmed)
#1.729746545566234e+19



# 13. What is the standard deviation of confirmed cases over time?
daily_std_confirmed = df.iloc[:, 11:].std().std()
print("\nStandard deviation of daily confirmed cases:", daily_std_confirmed)
#37583.33603268984



# 14. What is the total sum of confirmed cases across all dates?
total_confirmed = df.iloc[:, 11:].sum().sum()
print("\nTotal confirmed cases:", total_confirmed)
#53813347993

# 15. How many unique counties are there in the dataset?
print("\nNumber of unique counties:", df['Admin2'].nunique())
#1980

# 16. Which state has the highest total confirmed cases?
state_max_confirmed = df.groupby('Province_State').sum().iloc[:, 10:].sum(axis=1).idxmax()
print("\nState with highest total confirmed cases:", state_max_confirmed)
#California


# 17. Which state has the lowest total confirmed cases?
state_min_confirmed = df.groupby('Province_State').sum().iloc[:, 10:].sum(axis=1).idxmin()
print("\nState with lowest total confirmed cases:", state_min_confirmed)
#Diamond Princess

# 18. What date has the highest confirmed cases across all counties?
date_max_cases = df.iloc[:, 11:].sum().idxmax()
print("\nDate with highest confirmed cases:", date_max_cases)
#3/9/23


# 19. What date has the lowest confirmed cases across all counties?
date_min_cases = df.iloc[:, 11:].sum().idxmin()
print("\nDate with lowest confirmed cases:", date_min_cases)
#1/22/20


# 20. What is the correlation between population (FIPS) and confirmed cases?
print("\nCorrelation between 'FIPS' and confirmed cases:", df['FIPS'].corr(df.iloc[:, 11:].sum(axis=1)))
#-0.07680188363204962



# 21. What is the skewness of the confirmed cases?
print("\nSkewness of confirmed cases:", df.iloc[:, 11:].sum(axis=1).skew())
#16.44996568797362


# 22. What is the kurtosis of confirmed cases?
print("\nKurtosis of confirmed cases:", df.iloc[:, 11:].sum(axis=1).kurtosis())
#439.39551603577996

# 23. What is the difference between the highest and lowest confirmed cases for each record?
df['High_Low_Diff'] = df.iloc[:, 11:].max(axis=1) - df.iloc[:, 11:].min(axis=1)
print("\nFirst 5 High - Low differences in confirmed cases:")
print(df[['Admin2', 'High_Low_Diff']].head())
#    Admin2  High_L


# 24. What is the average daily confirmed case range (High - Low)?
print("\nAverage daily confirmed case range:", df['High_Low_Diff'].mean())
#31296.131956912028


# 25. How many records have confirmed cases greater than 10,000?
print("\nRecords with confirmed cases > 10,000:", len(df[df.iloc[:, 11:].sum(axis=1) > 10000]))
#3249


# 26. How many records have confirmed cases less than 1,000?
print("\nRecords with confirmed cases < 1,000:", len(df[df.iloc[:, 11:].sum(axis=1) < 1000]))
#88


# 27. What is the average percentage increase of confirmed cases per day?
df['Percentage_Change'] = df.iloc[:, 11:].pct_change(axis=1).mean(axis=1)
print("\nAverage daily percentage change of confirmed cases:", df['Percentage_Change'].mean())
#inf



# 28. What is the maximum daily percentage increase in confirmed cases?
print("\nMaximum daily percentage increase:", df['Percentage_Change'].max())
# inf

# 29. What is the minimum daily percentage increase in confirmed cases?
print("\nMinimum daily percentage increase:", df['Percentage_Change'].min())
#ANSWER: 0.015354526246637539

#
# 30. How many records show a decrease in confirmed cases over time?
print("\nRecords with decreasing confirmed cases:", len(df[df['Percentage_Change'] < 0]))
#ANSWER: 0 


# --- PLOTS ---

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

# Load the COVID-19 dataset
df = pd.read_csv('time_series_covid19_confirmed_US.csv')


#FIGURE 1
# Extract the date columns (they start from the 12th column onward)
dates = pd.to_datetime(df.columns[11:], format='%m/%d/%y')  # Convert columns to datetime format

# Sum the confirmed cases over all regions to get total confirmed cases for each date
total_cases_over_time = df.iloc[:, 11:].sum()

# Create the figure and plot
plt.figure(figsize=(10, 5))
plt.plot(dates, total_cases_over_time.values)  # Use the actual datetime values for the x-axis
plt.title('Total Confirmed COVID-19 Cases Over Time')
plt.xlabel('Date')
plt.ylabel('Confirmed Cases')

# Format the x-axis for better readability
plt.xticks(rotation=45)
plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=2))  # Show ticks every 2 months
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))  # Show Year-Month

plt.tight_layout()  # Adjust the layout
plt.show()



# Plot 2: Bar Plot of Total Confirmed Cases by State
cases_by_state = df.groupby('Province_State').sum().iloc[:, 10:].sum(axis=1)
plt.figure(figsize=(10, 5))
cases_by_state.plot(kind='bar')
plt.title('Total Confirmed Cases by State')
plt.xlabel('State')
plt.ylabel('Total Confirmed Cases')
plt.tight_layout()
plt.show()
plt.close()




# Plot 3: Heatmap of Confirmed Cases by State and Date
state_case_matrix = df.groupby('Province_State').sum().iloc[:, 10:]
plt.figure(figsize=(12, 8))
sns.heatmap(state_case_matrix, cmap='YlOrRd')
plt.title('Heatmap of Confirmed Cases by State and Date')
plt.xlabel('Date')
plt.ylabel('State')
plt.tight_layout()
plt.show()
plt.close()




# Plot 4: Histogram of Daily Percentage Changes in Confirmed Cases
# Ensure 'Percentage_Change' is calculated correctly
df['Percentage_Change'] = df.iloc[:, 11:].pct_change(axis=1).mean(axis=1)

# Check if the column was added correctly
print(df[['Percentage_Change']].head())

# Plot 4: Histogram of Daily Percentage Changes in Confirmed Cases
# Ensure 'Percentage_Change' is calculated correctly
df['Percentage_Change'] = df.iloc[:, 11:].pct_change(axis=1).mean(axis=1)
df_clean = df[~df['Percentage_Change'].isin([float('inf'), float('-inf')])]
df_clean = df_clean.dropna(subset=['Percentage_Change'])
plt.figure(figsize=(8, 5))
plt.hist(df_clean['Percentage_Change'], bins=30, color='blue', edgecolor='black')
plt.title('Distribution of Daily Percentage Change in Confirmed Cases')
plt.xlabel('Percentage Change')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()
plt.close()
